{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 ALPHAZERO ALGORITHM:\
\
-Run main.py to start entire algorithm.\
-The main difference between alphazero_compressedsensing and alphazero_compressedsensing_nonoise are in CSGame.py and CSState,. The nodes one can traverse to are different(available actions are different for a given state). In the no noise version, we can never pick the stopping action if ||A_Sx-y||^2_2. \
\
INPUT:\
- args dictionary in main.py dictates all parameters of alphazero. Change these in main.py before running algorithm.\
\
OUTPUT:\
- 1) neural network model and weights \'91best_model.json\'92, and \'91best_weights.h5\'92 in folder \'91network_checkpoint/\'91. Also outputs neural network model and weights across all iterations of alphazero in the same folder\
\
- 2) All self play games across all iterations in \'91training_data/\'91. The latest set of self play games is saved as \'91best.pth.tar\'92\
\
\
FEATURES ADDED:\
(May 31, 2018)\
-added functionality to remove Arena/model selection to select the next best neural network. Change\
 args[\'91Arena\'92] = False in main.py to turn Arena off.\
\
(June 11, 2018)\
-added functionality to load pre-existing, trained nn models, sensing matrices, and training data.\
\
BUG FIXES:\
(June 3, 2018)\
-changed x[0:rand_sparsity] = np.random.normal(0,1) \'97\'97\'97> x[0:rand_sparsity] = np.random.normal(0, 1, rand_sparsity). The previous code was generating the same value for all sparse entries\
\
(June 4, 2018)\
-added code in matrix A generation to normalize the columns. This is one of the criteria for using OMP on a sensing matrix. \
\
(June 14, 2018)\
-changed self.termreward = -np.linalg.norm(Game_args.obs_vector)**2 \'97\'97\'97> self.termreward = -self.args[\'91gamma\'92]*np.linalg.norm(Game_args.obs_vector)**2 in CSState.py. Forgot to multiply by scaling factor gamma for the reward received when NN chooses the stopping action at the initial state.\
\
}