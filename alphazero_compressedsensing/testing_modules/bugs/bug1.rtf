{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;\f1\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c100000\c100000\c100000;\cssrgb\c0\c0\c0;}
\margl1440\margr1440\vieww11460\viewh12460\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf2 \cb3 \CocoaLigature0 sichens-air:testing_modules sichenzhong$ python Testing_Coach.py\
Using TensorFlow backend.\
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\
\
length of trainExamples is: 3\
\
Action Indices: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\
Column_Indices: []\
\
Feature_dic: \
x_l2: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\
col_res_IP: [  8.04608784   4.27388646  18.15866185  -8.17355048   7.53267239\
   9.03979594   6.81167882   4.7132587   -8.17780579   5.31354978]\
\
state.p_as: [0.0, 0.3333333333333333, 0.041666666666666664, 0.0, 0.0, 0.0, 0.125, 0.3333333333333333, 0.16666666666666666, 0.0, 0.0]\
state.z: -48.116020933\
\
\
Action Indices: [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\
Column_Indices: [8]\
\
Feature_dic: \
x_l2: [ 0.          0.          0.          0.          0.          0.          0.\
  0.         -2.04453244  0.        ]\
col_res_IP: [  1.02690565e+01   4.56114316e+00   1.23144834e+01   1.04096101e+01\
   5.38325976e+00   3.66010951e+00   4.79902233e+00   9.60458958e+00\
   1.01662055e-15   2.94113244e+00]\
\
state.p_as: [0.14285714285714285, 0.07142857142857142, 0.03571428571428571, 0.14285714285714285, 0.14285714285714285, 0.10714285714285714, 0.07142857142857142, 0.10714285714285714, 0.0, 0.14285714285714285, 0.03571428571428571]\
state.z: -48.116020933\
\
\
Action Indices: [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.]\
Column_Indices: [8, 9]\
\
Feature_dic: \
x_l2: [ 0.          0.          0.          0.          0.          0.          0.\
  0.         -1.82977776  0.74026692]\
col_res_IP: [  8.96815012e+00   3.08081553e+00   1.16003592e+01   7.18828841e+00\
   6.57420554e+00   2.13277055e+00   4.69135993e+00   6.31615771e+00\
   3.37473615e-15   1.93181311e-15]\
\
state.p_as: [0.14285714285714285, 0.07142857142857142, 0.14285714285714285, 0.10714285714285714, 0.10714285714285714, 0.17857142857142858, 0.10714285714285714, 0.10714285714285714, 0.0, 0.0, 0.03571428571428571]\
state.z: -48.116020933\
\
The generated sparse vector is: [ 0.          2.16961636  2.16961636  0.          2.16961636  0.          0.\
  0.          0.          0.        ]
\f1\fs24 \cf0 \cb1 \CocoaLigature1 \
\
\ul NOTES\ulnone : In the above example, the stopping action was chosen at the last step but the corresponding state with action indices [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1] was not added to list of states. Since only two columns were chosen, and the stop action was taken, it is not a surprise that the propagated reward is so large (-48.116).\
\
\ul FIX:\ulnone  The final state with the stopping action chosen has been added to the list of trainingExamples in the method executeEpisode in Coach.py}