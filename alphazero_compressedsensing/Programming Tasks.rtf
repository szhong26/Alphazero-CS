{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww13640\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \ul \ulc0 Programming Tasks\ulnone \
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 - Finish writing MCTS and conduct some tests of module.\
- Write the Game.py object.\
- Write the NeuralNet.py object.\
\
Tentative meeting topics:\
	
\b Q
\b0 : How to represent output of neural network?\
	    Output has to be probability distribution of available actions. In go, the output is 361 neurons\
	    In our problem, we have much more available actions at every state. Namely, given a state,\
               we can choose any combination of 2, 3, 4 \'85. columns. This gives us O(2^n) number of\
	    actions at every state. 
\b Perhaps we can encode the output layer as having size equal to #columns
\b0 . \
               Choosing k columns at once in matching pursuit should be equivalent to not having any intermediary rewards. \
               \
	
\b Q: 
\b0 How to represent input of neural network and \ul what are we learning\ulnone ? The input needs to be \ul carefully\ulnone  chosen, because\
                this determines what our NN is learning. In Go, it is an array representation of the board over unique positions, so\
                the CNN can learn from patterns in the board given a position. Just having our input as leftover columns\
                should not be sufficient because
\b  
\b0 we should be learning from our specific position/state through the NN, \
                
\b which is mostly dictated by the observed vector y
\b0 . If we just have leftover columns and no information about y, \
                we would not be learning anything. Hence, our game state should factor in A, x(solution to ||Hx-y||_2 or ||Hx-y||_1\
                , where H are previously chosen columns), and y. \
\
	    Ideas for input:\
               1)A*x_t, where x_t is current solution we are at.\
\
	    Support recovery or full sparse vector recovery also will determine our state space, in that support recovery will\
	    allow us to design a less complicated state space? \
	     \
\
	
\b Personal Note:
\b0  Remember our main problem is: Given a signal y, find the sparsest x such that Ax = y. Given y,\
	the terminal rewards change!!! This is different from go, in that rewards do not change over games in go. This is\
           because y is \ul random\ulnone . 
\b We should formulate a CS game which is conducive to learning. 
\b0 \
\
- Dont forget to update what rewards are received at the end\'85\
  
\b Note:
\b0  While rewards are given at the end, we need to keep track of whether a state is a terminating state! This is encoded in\
            the input?\
- Continue to develop neural network side of code using tensorflow. Try first with ANN.\
- Test on small matrix examples on local machine first once coding is finished. \
- upload to github. \
}