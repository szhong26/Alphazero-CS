{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh11640\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 -This folder contains experiment for comparing OMPbootstrappedNN versus OMP algorithm.\
- The below contains relevant parameters for experiment.\
\
training args:\
	A: single 7 by 15 sensing matrix, each entry i.i.d N(0,1)\
	x: 500,000 test signals generated\
	    sparsity level is randomly generated between 1 and 6\
	   nonzero entries are generated uniformly U[0,1]\
	y = Ax\
\
For each y above, we use OMP for recovery, and at each step of OMP, we generate (x_S, lambda) pairs, where the corresponding label is a one hot vector of the next column chosen. In expectation, there are 500,000*6/2 = 1500000 training data(since sparsity is randomly generated between 1 and 6)\
\
In this experiment, we also have a validation dataset which is 100,000 generated signals.\
The graphs in this folder also contain curves for validation. \
\
bootstrap_NN args: \
	Input: absolute value of A^T*residual\
	          current sparse solution x_S\
	Hidden Neurons: 200 per layer, 2 layers. \
	Output: softmax probability distribution\
		  predicted reward (predicts -||x_0|| - gamma ||Ax* - y||_2^2, where x* is the final solution\
		  of OMP)\
	Training: epochs = 200\
		    lr = 0.001\
\
test_args:\
	- for each sparsity level (1 to 6), 1000 test signals x are generated. The location of the support 	is \
	  chosen randomly, and each nonzero is generated uniformly U[0,1].\
\
\
\
\
	\
		     \
	}